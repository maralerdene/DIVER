{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fkvivid/DIVER/blob/main/Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzg7nGm1FRLC"
      },
      "source": [
        "### 【Problem 1】Looking Back at Scratch\n",
        "Look back at your scratches so far and list what you needed to implement deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATqy7PhzFRLC"
      },
      "source": [
        "### Prepare the data set.\n",
        "We will use the Iris dataset that we have been using for some time.  \n",
        "The following sample code assumes that Iris.csv is in the same hierarchy.  \n",
        "https://www.kaggle.com/uciml/iris/data\n",
        "\n",
        "The target variable is Species, but we will only use the following two types out of the three available.\n",
        "\n",
        "* Iris-versicolor\n",
        "* Iris-virginica"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "3P1e0g4t7wMn",
        "outputId": "12fcbc94-e156-4f48-c3d1-968075e05c12"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ae7ec1c9-8ec9-45a4-b81a-79c22dbb07bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ae7ec1c9-8ec9-45a4-b81a-79c22dbb07bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Iris.csv to Iris.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Iris.csv': b'Id,SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species\\n1,5.1,3.5,1.4,0.2,Iris-setosa\\n2,4.9,3.0,1.4,0.2,Iris-setosa\\n3,4.7,3.2,1.3,0.2,Iris-setosa\\n4,4.6,3.1,1.5,0.2,Iris-setosa\\n5,5.0,3.6,1.4,0.2,Iris-setosa\\n6,5.4,3.9,1.7,0.4,Iris-setosa\\n7,4.6,3.4,1.4,0.3,Iris-setosa\\n8,5.0,3.4,1.5,0.2,Iris-setosa\\n9,4.4,2.9,1.4,0.2,Iris-setosa\\n10,4.9,3.1,1.5,0.1,Iris-setosa\\n11,5.4,3.7,1.5,0.2,Iris-setosa\\n12,4.8,3.4,1.6,0.2,Iris-setosa\\n13,4.8,3.0,1.4,0.1,Iris-setosa\\n14,4.3,3.0,1.1,0.1,Iris-setosa\\n15,5.8,4.0,1.2,0.2,Iris-setosa\\n16,5.7,4.4,1.5,0.4,Iris-setosa\\n17,5.4,3.9,1.3,0.4,Iris-setosa\\n18,5.1,3.5,1.4,0.3,Iris-setosa\\n19,5.7,3.8,1.7,0.3,Iris-setosa\\n20,5.1,3.8,1.5,0.3,Iris-setosa\\n21,5.4,3.4,1.7,0.2,Iris-setosa\\n22,5.1,3.7,1.5,0.4,Iris-setosa\\n23,4.6,3.6,1.0,0.2,Iris-setosa\\n24,5.1,3.3,1.7,0.5,Iris-setosa\\n25,4.8,3.4,1.9,0.2,Iris-setosa\\n26,5.0,3.0,1.6,0.2,Iris-setosa\\n27,5.0,3.4,1.6,0.4,Iris-setosa\\n28,5.2,3.5,1.5,0.2,Iris-setosa\\n29,5.2,3.4,1.4,0.2,Iris-setosa\\n30,4.7,3.2,1.6,0.2,Iris-setosa\\n31,4.8,3.1,1.6,0.2,Iris-setosa\\n32,5.4,3.4,1.5,0.4,Iris-setosa\\n33,5.2,4.1,1.5,0.1,Iris-setosa\\n34,5.5,4.2,1.4,0.2,Iris-setosa\\n35,4.9,3.1,1.5,0.1,Iris-setosa\\n36,5.0,3.2,1.2,0.2,Iris-setosa\\n37,5.5,3.5,1.3,0.2,Iris-setosa\\n38,4.9,3.1,1.5,0.1,Iris-setosa\\n39,4.4,3.0,1.3,0.2,Iris-setosa\\n40,5.1,3.4,1.5,0.2,Iris-setosa\\n41,5.0,3.5,1.3,0.3,Iris-setosa\\n42,4.5,2.3,1.3,0.3,Iris-setosa\\n43,4.4,3.2,1.3,0.2,Iris-setosa\\n44,5.0,3.5,1.6,0.6,Iris-setosa\\n45,5.1,3.8,1.9,0.4,Iris-setosa\\n46,4.8,3.0,1.4,0.3,Iris-setosa\\n47,5.1,3.8,1.6,0.2,Iris-setosa\\n48,4.6,3.2,1.4,0.2,Iris-setosa\\n49,5.3,3.7,1.5,0.2,Iris-setosa\\n50,5.0,3.3,1.4,0.2,Iris-setosa\\n51,7.0,3.2,4.7,1.4,Iris-versicolor\\n52,6.4,3.2,4.5,1.5,Iris-versicolor\\n53,6.9,3.1,4.9,1.5,Iris-versicolor\\n54,5.5,2.3,4.0,1.3,Iris-versicolor\\n55,6.5,2.8,4.6,1.5,Iris-versicolor\\n56,5.7,2.8,4.5,1.3,Iris-versicolor\\n57,6.3,3.3,4.7,1.6,Iris-versicolor\\n58,4.9,2.4,3.3,1.0,Iris-versicolor\\n59,6.6,2.9,4.6,1.3,Iris-versicolor\\n60,5.2,2.7,3.9,1.4,Iris-versicolor\\n61,5.0,2.0,3.5,1.0,Iris-versicolor\\n62,5.9,3.0,4.2,1.5,Iris-versicolor\\n63,6.0,2.2,4.0,1.0,Iris-versicolor\\n64,6.1,2.9,4.7,1.4,Iris-versicolor\\n65,5.6,2.9,3.6,1.3,Iris-versicolor\\n66,6.7,3.1,4.4,1.4,Iris-versicolor\\n67,5.6,3.0,4.5,1.5,Iris-versicolor\\n68,5.8,2.7,4.1,1.0,Iris-versicolor\\n69,6.2,2.2,4.5,1.5,Iris-versicolor\\n70,5.6,2.5,3.9,1.1,Iris-versicolor\\n71,5.9,3.2,4.8,1.8,Iris-versicolor\\n72,6.1,2.8,4.0,1.3,Iris-versicolor\\n73,6.3,2.5,4.9,1.5,Iris-versicolor\\n74,6.1,2.8,4.7,1.2,Iris-versicolor\\n75,6.4,2.9,4.3,1.3,Iris-versicolor\\n76,6.6,3.0,4.4,1.4,Iris-versicolor\\n77,6.8,2.8,4.8,1.4,Iris-versicolor\\n78,6.7,3.0,5.0,1.7,Iris-versicolor\\n79,6.0,2.9,4.5,1.5,Iris-versicolor\\n80,5.7,2.6,3.5,1.0,Iris-versicolor\\n81,5.5,2.4,3.8,1.1,Iris-versicolor\\n82,5.5,2.4,3.7,1.0,Iris-versicolor\\n83,5.8,2.7,3.9,1.2,Iris-versicolor\\n84,6.0,2.7,5.1,1.6,Iris-versicolor\\n85,5.4,3.0,4.5,1.5,Iris-versicolor\\n86,6.0,3.4,4.5,1.6,Iris-versicolor\\n87,6.7,3.1,4.7,1.5,Iris-versicolor\\n88,6.3,2.3,4.4,1.3,Iris-versicolor\\n89,5.6,3.0,4.1,1.3,Iris-versicolor\\n90,5.5,2.5,4.0,1.3,Iris-versicolor\\n91,5.5,2.6,4.4,1.2,Iris-versicolor\\n92,6.1,3.0,4.6,1.4,Iris-versicolor\\n93,5.8,2.6,4.0,1.2,Iris-versicolor\\n94,5.0,2.3,3.3,1.0,Iris-versicolor\\n95,5.6,2.7,4.2,1.3,Iris-versicolor\\n96,5.7,3.0,4.2,1.2,Iris-versicolor\\n97,5.7,2.9,4.2,1.3,Iris-versicolor\\n98,6.2,2.9,4.3,1.3,Iris-versicolor\\n99,5.1,2.5,3.0,1.1,Iris-versicolor\\n100,5.7,2.8,4.1,1.3,Iris-versicolor\\n101,6.3,3.3,6.0,2.5,Iris-virginica\\n102,5.8,2.7,5.1,1.9,Iris-virginica\\n103,7.1,3.0,5.9,2.1,Iris-virginica\\n104,6.3,2.9,5.6,1.8,Iris-virginica\\n105,6.5,3.0,5.8,2.2,Iris-virginica\\n106,7.6,3.0,6.6,2.1,Iris-virginica\\n107,4.9,2.5,4.5,1.7,Iris-virginica\\n108,7.3,2.9,6.3,1.8,Iris-virginica\\n109,6.7,2.5,5.8,1.8,Iris-virginica\\n110,7.2,3.6,6.1,2.5,Iris-virginica\\n111,6.5,3.2,5.1,2.0,Iris-virginica\\n112,6.4,2.7,5.3,1.9,Iris-virginica\\n113,6.8,3.0,5.5,2.1,Iris-virginica\\n114,5.7,2.5,5.0,2.0,Iris-virginica\\n115,5.8,2.8,5.1,2.4,Iris-virginica\\n116,6.4,3.2,5.3,2.3,Iris-virginica\\n117,6.5,3.0,5.5,1.8,Iris-virginica\\n118,7.7,3.8,6.7,2.2,Iris-virginica\\n119,7.7,2.6,6.9,2.3,Iris-virginica\\n120,6.0,2.2,5.0,1.5,Iris-virginica\\n121,6.9,3.2,5.7,2.3,Iris-virginica\\n122,5.6,2.8,4.9,2.0,Iris-virginica\\n123,7.7,2.8,6.7,2.0,Iris-virginica\\n124,6.3,2.7,4.9,1.8,Iris-virginica\\n125,6.7,3.3,5.7,2.1,Iris-virginica\\n126,7.2,3.2,6.0,1.8,Iris-virginica\\n127,6.2,2.8,4.8,1.8,Iris-virginica\\n128,6.1,3.0,4.9,1.8,Iris-virginica\\n129,6.4,2.8,5.6,2.1,Iris-virginica\\n130,7.2,3.0,5.8,1.6,Iris-virginica\\n131,7.4,2.8,6.1,1.9,Iris-virginica\\n132,7.9,3.8,6.4,2.0,Iris-virginica\\n133,6.4,2.8,5.6,2.2,Iris-virginica\\n134,6.3,2.8,5.1,1.5,Iris-virginica\\n135,6.1,2.6,5.6,1.4,Iris-virginica\\n136,7.7,3.0,6.1,2.3,Iris-virginica\\n137,6.3,3.4,5.6,2.4,Iris-virginica\\n138,6.4,3.1,5.5,1.8,Iris-virginica\\n139,6.0,3.0,4.8,1.8,Iris-virginica\\n140,6.9,3.1,5.4,2.1,Iris-virginica\\n141,6.7,3.1,5.6,2.4,Iris-virginica\\n142,6.9,3.1,5.1,2.3,Iris-virginica\\n143,5.8,2.7,5.1,1.9,Iris-virginica\\n144,6.8,3.2,5.9,2.3,Iris-virginica\\n145,6.7,3.3,5.7,2.5,Iris-virginica\\n146,6.7,3.0,5.2,2.3,Iris-virginica\\n147,6.3,2.5,5.0,1.9,Iris-virginica\\n148,6.5,3.0,5.2,2.0,Iris-virginica\\n149,6.2,3.4,5.4,2.3,Iris-virginica\\n150,5.9,3.0,5.1,1.8,Iris-virginica\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_xquP96FRLD"
      },
      "source": [
        "### 【Problem 2】Consider the correspondence between Scratch and TensorFlow.\n",
        "Look at the following sample code to see how the \"things necessary to implement deep learning\" enumerated earlier are implemented in TensorFlow.\n",
        "\n",
        "Summarize it in a few simple words. It does not necessarily have to be a simple one-to-one correspondence.\n",
        "\n",
        "Sample code  \n",
        "It has been tested between versions 1.5 and 1.14."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd2ylJvCFRLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e48bae-4d0e-4f64-f16f-366349523a69"
      },
      "source": [
        "# Import as Tensorflow Series 1 (disable Series 2)\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7J1CoLSFRLE"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    Iterator to get the mini-batch\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : ndarray of the following form, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : ndarray of the following form, shape (n_samples, 1)\n",
        "      correct value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      Seeding random numbers in NumPy\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28HObDtWFRLF"
      },
      "source": [
        "def example_net(x):\n",
        "    \"\"\"\n",
        "    A simple three-layer neural network\n",
        "    \"\"\"\n",
        "    # Declaring weights and biases\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    \n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    \n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    # tf.add and + are equivalent\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] \n",
        "    \n",
        "    return layer_output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkH7WlAJFRLG",
        "outputId": "47c98e58-34e8-43c7-8db5-9e370ae047b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "Binary classification of Iris dataset using a neural network implemented in TensorFlow.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load a data set\n",
        "dataset_path =\"./Iris.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Extract conditions from data frame\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "\n",
        "# Convert labels to numbers\n",
        "y[y=='Iris-versicolor'] = 0\n",
        "y[y=='Iris-virginica'] = 1\n",
        "y = y.astype(np.int)[:, np.newaxis]\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# Further split into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "    \n",
        "# Configure hyperparameters\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "# Determine the form of the arguments to be passed to the computational graph\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# train's mini-batch iterator\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Load the network structure                               \n",
        "logits = example_net(X)\n",
        "\n",
        "# Objective function\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "# Optimization methods\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Estimation results\n",
        "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "\n",
        "# Index value calculation\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variable\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Run a computational graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # Loop per epoch\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # Loop for each mini-batch\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 21.4288, val_loss : 53.6056, acc : 0.750, val_acc : 0.375\n",
            "Epoch 1, loss : 19.8665, val_loss : 9.7025, acc : 0.250, val_acc : 0.688\n",
            "Epoch 2, loss : 1.4503, val_loss : 8.7329, acc : 0.750, val_acc : 0.375\n",
            "Epoch 3, loss : 0.0000, val_loss : 0.0066, acc : 1.000, val_acc : 1.000\n",
            "Epoch 4, loss : 0.0000, val_loss : 0.5361, acc : 1.000, val_acc : 0.875\n",
            "Epoch 5, loss : 0.0000, val_loss : 0.2599, acc : 1.000, val_acc : 0.938\n",
            "Epoch 6, loss : 0.0000, val_loss : 0.1106, acc : 1.000, val_acc : 0.938\n",
            "Epoch 7, loss : 0.0000, val_loss : 0.3623, acc : 1.000, val_acc : 0.938\n",
            "Epoch 8, loss : 0.0000, val_loss : 0.0056, acc : 1.000, val_acc : 1.000\n",
            "Epoch 9, loss : 0.0000, val_loss : 0.7935, acc : 1.000, val_acc : 0.875\n",
            "test_acc : 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0ht0K6nFRLI"
      },
      "source": [
        "* There was initialization of weights and biases.  \n",
        "  -->127.  \n",
        "     init = tf.global_variables_initializer() to initialize parameters\n",
        "\n",
        "\n",
        "* Needed to loop through epochs.  \n",
        "  -->132.  \n",
        "    for epoch in range(num_epochs): to loop for epochs\n",
        "  \n",
        "  \n",
        "* Decided the number of nodes and activation function for each layer.  \n",
        "  -->68-76.  \n",
        "  Set parameters such as number of nodes.  \n",
        "  -->90-107.  \n",
        "  Define activation function with layer_1 = tf.nn.relu(layer_1)\n",
        "\n",
        "  \n",
        "* Training data is mini-batch size.  \n",
        "  -->29.  \n",
        "  Define GetMiniBatch class, 138. calculate for each mini-batch.\n",
        "  \n",
        "\n",
        "* Linear combination.  \n",
        "  -->102,104.  \n",
        "  layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "  \n",
        "  \n",
        "* Assigned linearly combined values to the activation function and passed the result to the next layer (forward propagation).  \n",
        "  -->104,107.  \n",
        "  layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "  \n",
        "  \n",
        "* Calculated the loss function.  \n",
        "  -->115,141.  \n",
        "  loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,logits=logits))\n",
        "  \n",
        "  \n",
        "* Updated weights and biases (error back propagation method).  \n",
        "  -->118,119.  \n",
        "  AdamOptimizer(learning_rate=learning_rate) optimizer = tf.train.  \n",
        "  train_op = optimizer.minimize(loss_op)  \n",
        "   \n",
        "   \n",
        "* Predicted against validation data using learned parameters.  \n",
        "  -->122,148.  \n",
        "  test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXv1T0ArFRLI"
      },
      "source": [
        "## Applying to other datasets\n",
        "There are several small data sets that we have been working with.\n",
        "Please rewrite the above sample code to create a neural network that will train and estimate on these.\n",
        "* Iris (using all three objective variables)\n",
        "* House Prices\n",
        "All datasets should be divided into three types: train, val, and test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLshx35zFRLI"
      },
      "source": [
        "### 【Problem 3】Create a model for Iris with all three objective variables\n",
        "In the train.csv of the Iris data set, create a model that can classify all three types included in the objective variable Species.\n",
        "\n",
        "* Iris Species\n",
        "\n",
        "Consider the difference between a two-class classification and a classification of three or more classes. Find out how it can be rewritten in TensorFlow by referring to the official documentation.\n",
        "\n",
        "Hint.\n",
        "\n",
        "The following two parts are specific to two-class classification.\n",
        "\n",
        "Please check the official documentation for the methods as follows.\n",
        "* https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "* https://www.tensorflow.org/api_docs/python/tf/math/sign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pqv2ggXFRLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "892f75c6-c92e-4258-8a08-b7e9d4c9ad73"
      },
      "source": [
        "\"\"\"\n",
        "Problem 3: Using a neural network implemented in TensorFlow to classify the Iris dataset as multi-level.\n",
        "\"\"\"\n",
        "# Load a data set\n",
        "dataset_path =\"./Iris/Iris.csv\"\n",
        "df_iris = pd.read_csv(dataset_path)\n",
        "\n",
        "# Extract conditions from data frame\n",
        "df_iris = df_iris[(df_iris[\"Species\"] == \"Iris-setosa\")\n",
        "                  |(df_iris[\"Species\"] == \"Iris-versicolor\")\n",
        "                  |(df_iris[\"Species\"] == \"Iris-virginica\")\n",
        "                 ]\n",
        "y = df_iris[\"Species\"]\n",
        "X = df_iris.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "\n",
        "# Convert labels to numbers\n",
        "y[y=='Iris-setosa'] = 0\n",
        "y[y=='Iris-versicolor'] = 1\n",
        "y[y=='Iris-virginica'] = 2\n",
        "\n",
        "# One-hot encoding of correct label value\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y = enc.fit_transform(y[:, np.newaxis])\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# Further split into train and val\n",
        "X_train, X_val, y_train, y_val = \\\n",
        "train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a82118435585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load a data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"./Iris/Iris.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_iris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Extract conditions from data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Iris/Iris.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myU4ZGGaFRLK",
        "outputId": "c2fe7548-3f6d-4153-97d6-e9e290bd2a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('y.shape:',y.shape)\n",
        "print('X.shape:',X.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y.shape: (100, 1)\n",
            "X.shape: (?, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH0oA2-1FRLK",
        "outputId": "07faa371-62a8-4429-f86a-5202f95cee10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Plot Train data\n",
        "import seaborn as sns\n",
        "sns.pairplot(df_iris,hue='Species');"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-988f8fc28a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot Train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_iris\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Species'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_iris' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQZ6KlHCFRLK"
      },
      "source": [
        "# Configure hyperparameters\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 3\n",
        "\n",
        "# Determine the form of the arguments to be passed to the computational graph\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# train's mini-batch iterator\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Load the network structure                               \n",
        "logits = example_net(X)\n",
        "\n",
        "# Objective function\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "                         labels=Y, logits=logits)\n",
        "                        )\n",
        "\n",
        "# Optimization methods\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Estimation results\n",
        "correct_pred = tf.equal(tf.argmax(Y,1), tf.argmax(tf.nn.softmax(logits),1))\n",
        "\n",
        "# Index value calculation\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variable\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Run a computational graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Loop per epoch\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        \n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            \n",
        "            # Loop for each mini-batch\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run(\n",
        "                [loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y}\n",
        "            )\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "            \n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        \n",
        "        val_loss, val_acc = sess.run(\n",
        "            [loss_op, accuracy], feed_dict={X: X_val, Y: y_val}\n",
        "        )\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\"\n",
        "              .format(epoch, loss, val_loss, acc, val_acc))\n",
        "        \n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnJJI2ksFRLL"
      },
      "source": [
        "### 【Problem 4】Create a model of House Prices\n",
        "Create a model using House Prices, the dataset for the regression problem.\n",
        "  \n",
        "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
        "  \n",
        "Download the file train.csv and use SalePrice as the objective variable and GrLivArea and YearBuilt as explanatory variables. You can add more explanatory variables if you like.\n",
        "\n",
        "Please take into account the difference between a classification problem and a regression problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDsb2D16FRLM"
      },
      "source": [
        "\"\"\"\n",
        "Problem 4: Predicting House Price data using a neural network implemented in TensorFlow\n",
        "\"\"\"\n",
        "# Load a data set\n",
        "dataset_path =\"./house_prices_advanced_regression_techniques/train.csv\"\n",
        "df_house = pd.read_csv(dataset_path)\n",
        "\n",
        "# Extract conditions from data frame\n",
        "y = df_house[['SalePrice']]\n",
        "X = df_house[['GrLivArea','YearBuilt']]\n",
        "y = np.array(np.log1p(y))\n",
        "X = np.array(np.log1p(X))\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# Further split into train and val\n",
        "X_train, X_val, y_train, y_val = \\\n",
        "train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cDiUEAtFRLM"
      },
      "source": [
        "print('y.shape:',y.shape)\n",
        "print('X.shape:',X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2SFtRzgFRLM",
        "outputId": "6e875695-fb22-4322-9bbc-ca8452444707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# Plot Train data\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "fig,ax = plt.subplots(1,2,sharey=True,figsize=(16, 5))\n",
        "\n",
        "ax[0].scatter(X_train[:,0],y_train)\n",
        "ax[1].scatter(X_train[:,1],y_train);"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpBHD3D6FRLM"
      },
      "source": [
        "def regression_net(x):\n",
        "    \"\"\"\n",
        "    A simple three-layer neural network\n",
        "    \"\"\"\n",
        "    # Declaring weights and biases\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    \n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    \n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    # tf.add and + are equivalent\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] \n",
        "    \n",
        "    return layer_output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj0Q2FW9FRLN",
        "outputId": "e36610b7-b7b5-4f58-c437-a7ec5f8f4b2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Configure hyperparameters\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "# Determine the form of the arguments to be passed to the computational graph\n",
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "Y = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "# train's mini-batch iterator\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Load the network structure                               \n",
        "logits = regression_net(X)\n",
        "\n",
        "# Objective function\n",
        "loss_op = tf.reduce_mean(tf.square(logits - Y))\n",
        "\n",
        "# Optimization methods\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Index value calculation\n",
        "mean_square_error = tf.reduce_mean(tf.square(logits - Y))\n",
        "\n",
        "# Initialize the variable\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Run a computational graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Loop per epoch\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_mse = 0\n",
        "        \n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            \n",
        "            # Loop for each mini-batch\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            \n",
        "            loss, mse = sess.run([loss_op, mean_square_error],\n",
        "                                 feed_dict={X: mini_batch_x, Y: mini_batch_y}\n",
        "            )\n",
        "            total_loss += loss\n",
        "            total_mse += mse\n",
        "            \n",
        "        total_loss /= n_samples\n",
        "        total_mse /= n_samples\n",
        "        \n",
        "        val_loss, val_mse = sess.run([loss_op, mean_square_error],\n",
        "                                     feed_dict={X: X_val, Y: y_val}\n",
        "        )\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, mse : {:.3f}, val_mse : {:.3f}\"\n",
        "              .format(epoch, loss, val_loss, mse, val_mse))\n",
        "    test_mse = sess.run(mean_square_error, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_mse : {:.3f}\".format(test_mse))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 2560.0999, val_loss : 645.1661, mse : 2560.100, val_mse : 645.166\n",
            "Epoch 1, loss : 616.1554, val_loss : 635.3689, mse : 616.155, val_mse : 635.369\n",
            "Epoch 2, loss : 1559.3174, val_loss : 400.0242, mse : 1559.317, val_mse : 400.024\n",
            "Epoch 3, loss : 295.3759, val_loss : 227.0753, mse : 295.376, val_mse : 227.075\n",
            "Epoch 4, loss : 774.6631, val_loss : 235.4555, mse : 774.663, val_mse : 235.455\n",
            "Epoch 5, loss : 126.2909, val_loss : 100.0781, mse : 126.291, val_mse : 100.078\n",
            "Epoch 6, loss : 294.1947, val_loss : 118.4897, mse : 294.195, val_mse : 118.490\n",
            "Epoch 7, loss : 40.5826, val_loss : 25.2480, mse : 40.583, val_mse : 25.248\n",
            "Epoch 8, loss : 36.8251, val_loss : 26.5389, mse : 36.825, val_mse : 26.539\n",
            "Epoch 9, loss : 37.0581, val_loss : 37.3719, mse : 37.058, val_mse : 37.372\n",
            "test_mse : 19.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsWr7W-SFRLN"
      },
      "source": [
        "### 【Problem 5】Create a model for MNIST\n",
        "Create a model to classify the MNIST used in the neural network scratch.\n",
        "\n",
        "It is the same as the previous Iris in terms of classification of three or more classes. The difference is that the input is an image.\n",
        "\n",
        "Please aim to reproduce the model implemented in Scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugRDxhScFRLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34ade644-75cf-4939-e99b-4a47c2a19c50"
      },
      "source": [
        "\"\"\"\n",
        "Problem 5: Classify MNIST data using a neural network implemented in TensorFlow.\n",
        "\"\"\"\n",
        "# Download the MNIST dataset\n",
        "from keras.datasets import mnist\n",
        "(X, y), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN7qbDMkFRLN",
        "outputId": "68d80d84-9fee-4cf4-8597-3e94c2e99c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the data\n",
        "print(X.shape) # (60000, 28, 28)\n",
        "print(X.shape) # (10000, 28, 28)\n",
        "print(X[0].dtype) # uint8"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 28, 28)\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tobGz1-CFRLN",
        "outputId": "8a4ff5ee-ed17-4657-d0b4-8369ac1add20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Smoothing\n",
        "X = X.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "print(X.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1eWNqMMFRLO",
        "outputId": "0e9914d6-46e2-45ce-c01d-1cc6e5606c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Type conversion, normalization\n",
        "X = X.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X /= 255\n",
        "X_test /= 255\n",
        "print(X.max()) # 1.0\n",
        "print(X.min()) # 0.0"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vke5c-9NFRLO",
        "outputId": "d0cec729-4319-488c-9928-6879dca28d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
        "y_test = enc.transform(y_test[:, np.newaxis])\n",
        "print(y.shape) # (60000,)\n",
        "print(y_one_hot.shape) # (60000, 10)\n",
        "print(y_one_hot.dtype) # float64"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuNLZvsUFRLO",
        "outputId": "44acd28f-805c-4a33-c58e-5553dc26221b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y_one_hot, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n",
            "(48000, 10)\n",
            "(12000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hdjlE6qFRLO"
      },
      "source": [
        "def lenet(x):\n",
        "    \"\"\"\n",
        "    CNN\n",
        "    \"\"\"\n",
        "    # Declaring weights and biases\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([5,5,1,6])),\n",
        "        'w2': tf.Variable(tf.random_normal([5,5,6,16])),\n",
        "        'w3': tf.Variable(tf.random_normal([7*7*16, 120])),\n",
        "        'w4': tf.Variable(tf.random_normal([120, 84])),\n",
        "        'w5': tf.Variable(tf.random_normal([84, n_classes]))\n",
        "    }\n",
        "    \n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([6])),\n",
        "        'b2': tf.Variable(tf.random_normal([16])),\n",
        "        'b3': tf.Variable(tf.random_normal([120])),\n",
        "        'b4': tf.Variable(tf.random_normal([84])),\n",
        "        'b5': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    \n",
        "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
        "    conve_1 = tf.add(tf.nn.conv2d(x, weights['w1'],strides=[1,1,1,1],\n",
        "                                  padding='SAME'),\n",
        "                     biases['b1'])\n",
        "    \n",
        "    conve_1 = tf.nn.relu(conve_1)\n",
        "    \n",
        "    pooli_1 = tf.nn.pool(conve_1, window_shape=[2,2],strides=[2,2],\n",
        "                         pooling_type='MAX', padding='VALID')\n",
        "    \n",
        "    conve_2 = tf.add(tf.nn.conv2d(pooli_1, weights['w2'],strides=[1,1,1,1],\n",
        "                                  padding='SAME'),\n",
        "                     biases['b2'])\n",
        "    \n",
        "    conve_2 = tf.nn.relu(conve_2)\n",
        "    \n",
        "    pooli_2 = tf.nn.pool(conve_2, window_shape=[2,2],strides=[2,2],\n",
        "                         pooling_type='MAX', padding='VALID')\n",
        "    \n",
        "    x_reshape = tf.reshape(pooli_2, [-1,7*7*16])\n",
        "    layer_1 = tf.add(tf.matmul(x_reshape, weights['w3']), biases['b3'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w4']), biases['b4'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    # tf.add and + are equivalent\n",
        "    layer_output = tf.matmul(layer_2, weights['w5']) + biases['b5'] \n",
        "    \n",
        "    return layer_output"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "lQ_x9UglFRLO",
        "outputId": "e020856e-a7da-4fca-e87e-b5882f6208e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Configure hyperparameters\n",
        "learning_rate = 0.01\n",
        "batch_size = 200\n",
        "num_epochs = 30\n",
        "\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 10\n",
        "\n",
        "# Determine the form of the arguments to be passed to the computational graph\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# train's mini-batch iterator\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Load the network structure                               \n",
        "logits = lenet(X)\n",
        "\n",
        "# Objective function\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "                         labels=Y, logits=logits)\n",
        "                        )\n",
        "\n",
        "# Optimization methods\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Estimation results\n",
        "correct_pred = tf.equal(tf.argmax(Y,1), tf.argmax(tf.nn.softmax(logits),1))\n",
        "\n",
        "# Index value calculation\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variable\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Run a computational graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Loop per epoch\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        \n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            \n",
        "            # Loop for each mini-batch\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run(\n",
        "                [loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "            \n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "    \n",
        "        val_loss, val_acc = sess.run(\n",
        "            [loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        \n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\"\n",
        "             .format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 176.5230, val_loss : 189.6576, acc : 0.850, val_acc : 0.834\n",
            "Epoch 1, loss : 74.2056, val_loss : 91.7985, acc : 0.890, val_acc : 0.891\n",
            "Epoch 2, loss : 55.5757, val_loss : 67.3523, acc : 0.915, val_acc : 0.900\n",
            "Epoch 3, loss : 39.2660, val_loss : 47.1562, acc : 0.935, val_acc : 0.919\n",
            "Epoch 4, loss : 41.1170, val_loss : 38.9048, acc : 0.915, val_acc : 0.926\n",
            "Epoch 5, loss : 23.4336, val_loss : 30.0402, acc : 0.950, val_acc : 0.935\n",
            "Epoch 6, loss : 18.0731, val_loss : 26.1876, acc : 0.955, val_acc : 0.938\n",
            "Epoch 7, loss : 12.9544, val_loss : 20.9767, acc : 0.960, val_acc : 0.943\n",
            "Epoch 8, loss : 10.8722, val_loss : 18.7001, acc : 0.945, val_acc : 0.945\n",
            "Epoch 9, loss : 6.7474, val_loss : 17.0014, acc : 0.965, val_acc : 0.949\n",
            "Epoch 10, loss : 5.7916, val_loss : 15.7028, acc : 0.955, val_acc : 0.950\n",
            "Epoch 11, loss : 6.1213, val_loss : 14.7780, acc : 0.940, val_acc : 0.950\n",
            "Epoch 12, loss : 2.1485, val_loss : 13.7267, acc : 0.960, val_acc : 0.952\n",
            "Epoch 13, loss : 2.5963, val_loss : 12.0202, acc : 0.965, val_acc : 0.953\n",
            "Epoch 14, loss : 2.2254, val_loss : 11.5084, acc : 0.975, val_acc : 0.953\n",
            "Epoch 15, loss : 2.6372, val_loss : 11.5582, acc : 0.950, val_acc : 0.948\n",
            "Epoch 16, loss : 0.3615, val_loss : 9.3042, acc : 0.990, val_acc : 0.957\n",
            "Epoch 17, loss : 1.5137, val_loss : 8.8159, acc : 0.980, val_acc : 0.957\n",
            "Epoch 18, loss : 1.0504, val_loss : 8.6799, acc : 0.980, val_acc : 0.959\n",
            "Epoch 19, loss : 0.7708, val_loss : 8.6712, acc : 0.975, val_acc : 0.957\n",
            "Epoch 20, loss : 0.9133, val_loss : 8.1840, acc : 0.970, val_acc : 0.957\n",
            "Epoch 21, loss : 3.4092, val_loss : 7.4941, acc : 0.970, val_acc : 0.961\n",
            "Epoch 22, loss : 0.6124, val_loss : 7.5245, acc : 0.990, val_acc : 0.960\n",
            "Epoch 23, loss : 0.2546, val_loss : 6.4159, acc : 0.985, val_acc : 0.963\n",
            "Epoch 24, loss : 0.1880, val_loss : 7.7360, acc : 0.990, val_acc : 0.955\n",
            "Epoch 25, loss : 0.7584, val_loss : 5.8635, acc : 0.985, val_acc : 0.964\n",
            "Epoch 26, loss : 1.2365, val_loss : 5.3651, acc : 0.975, val_acc : 0.968\n",
            "Epoch 27, loss : 0.8979, val_loss : 5.3325, acc : 0.985, val_acc : 0.968\n",
            "Epoch 28, loss : 0.7380, val_loss : 6.6631, acc : 0.980, val_acc : 0.956\n",
            "Epoch 29, loss : 0.2176, val_loss : 5.5341, acc : 0.995, val_acc : 0.966\n",
            "test_acc : 0.967\n"
          ]
        }
      ]
    }
  ]
}