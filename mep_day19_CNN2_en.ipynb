{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "目次",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "428px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "mep_day19_CNN2_en.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fkvivid/DIVER/blob/main/mep_day19_CNN2_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKpJ0HshwK59"
      },
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluation index\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ6ECcWdwK5-",
        "outputId": "77716ec4-e0ba-47e2-bacb-8a45edf6be8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download the MNIST dataset\n",
        "from keras.datasets import mnist\n",
        "(X, y), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqBOBuCiwK5-",
        "outputId": "de8d2406-b65a-42da-938a-a8ea4eaf7132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the data\n",
        "print(X.shape) # (60000, 28, 28)\n",
        "print(X.shape) # (10000, 28, 28)\n",
        "print(X[0].dtype) # uint8"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 28, 28)\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2RmCiqawK6A",
        "outputId": "8c64f357-5d10-4b5c-b4b2-1fbbabfeab9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Type conversion, normalization\n",
        "X = X.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X /= 255\n",
        "X_test /= 255\n",
        "print(X.max()) # 1.0\n",
        "print(X.min()) # 0.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0uQj2znwK6A",
        "outputId": "41b7b8d5-22a0-4d1b-d028-0c91730102f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# One-hot encoding of correct label value\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y.shape) # (60000,)\n",
        "print(y_one_hot.shape) # (60000, 10)\n",
        "print(y_one_hot.dtype) # float64"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpkwfoPswK6B",
        "outputId": "6be298a4-31fe-4edb-fc98-cd7aadfe85cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Split into training data and validation data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y_one_hot, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 28, 28)\n",
            "(12000, 28, 28)\n",
            "(48000, 10)\n",
            "(12000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbqbCRZ4wK6B"
      },
      "source": [
        "### Preparing for NN classes and other activities so far"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEIcp2bPwK6C"
      },
      "source": [
        "#### All binding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duKjHNocwK6C"
      },
      "source": [
        "class FC:\n",
        "    \"\"\"\n",
        "    Fully connected layers from number of nodes n_nodes1 to n_nodes2\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      Number of nodes in the previous layer\n",
        "    n_nodes2 : int\n",
        "      Number of nodes in subsequent layers\n",
        "    initializer : Instances of initialization methods\n",
        "    optimizer : Instances of optimization methods\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
        "        \n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        # Initialize.\n",
        "        # Use the initializer method to initialize self.W and self.B\n",
        "        self.W = self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
        "        self.B = self.initializer.B(self.n_nodes2)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Forward\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "            Input\n",
        "        Returns\n",
        "        ----------\n",
        "        A : ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "            Output\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.A = np.dot(self.X,self.W) + self.B\n",
        "        \n",
        "        return self.activation.forward(self.A)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        Backward\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "            The gradient flowed in from behind.\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "            forward slope\n",
        "        \"\"\"\n",
        "        dA = self.activation.backward(dZ)\n",
        "        self.dB = np.mean(dA,axis=0)\n",
        "        self.dW = np.dot(self.X.T,dA)/len(self.X)\n",
        "        dZ = np.dot(dA,self.W.T)\n",
        "        \n",
        "        # Update\n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return dZ"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmW0YtuQwK6C"
      },
      "source": [
        "#### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD3iuDwMwK6D"
      },
      "source": [
        "class SimpleInitializerConv2d:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self, F, C, FH, FW):\n",
        "        \"\"\"\n",
        "        Initializing weights\n",
        "        Parameters\n",
        "        ----------\n",
        "        \n",
        "        Returns\n",
        "        ----------\n",
        "        W : weight\n",
        "        \"\"\"\n",
        "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
        "    \n",
        "    def B(self, F):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : bias\n",
        "        \"\"\"\n",
        "        return np.zeros(F)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgMADoK2wK6D"
      },
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Initializing weights\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in subsequent layers\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W : weight\n",
        "        \"\"\"\n",
        "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in subsequent layers\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : bias\n",
        "        \"\"\"\n",
        "        return np.zeros(n_nodes2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILn8pHVEwK6D"
      },
      "source": [
        "class HeInitializer():\n",
        "    \"\"\"\n",
        "    Initialization of weights by He\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Initializing weights\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in subsequent layers\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W : weight\n",
        "        \"\"\"\n",
        "        return np.random.randn(n_nodes1, n_nodes2)*np.sqrt(2/n_nodes1)\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in subsequent layers\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : bias\n",
        "        \"\"\"\n",
        "        return np.zeros(n_nodes2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNM2Pm7ywK6E"
      },
      "source": [
        "#### optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiF2CLhvwK6E"
      },
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    stochastic gradient descent method\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, layer):\n",
        "        \"\"\"\n",
        "        Updating the weights and biases of a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : An instance of the layer before the update\n",
        "        \"\"\"\n",
        "        layer.W -= self.lr*layer.dW\n",
        "        layer.B -= self.lr*layer.dB\n",
        "        \n",
        "        return layer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--IzRaSSwK6E"
      },
      "source": [
        "class AdaGrad:\n",
        "    \"\"\"\n",
        "    stochastic gradient descent method\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.hW = 0\n",
        "        self.hB = 0\n",
        "        \n",
        "    def update(self, layer):\n",
        "        \"\"\"\n",
        "        Updating the weights and biases of a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : An instance of the layer before the update\n",
        "        \"\"\"\n",
        "        self.hW += layer.dW*layer.dW\n",
        "        self.hB = layer.dB*layer.dB\n",
        "    \n",
        "        layer.W -= self.lr*layer.dW/(np.sqrt(self.hW) +1e-7)\n",
        "        layer.B -= self.lr*layer.dB/(np.sqrt(self.hB) +1e-7)\n",
        "        \n",
        "        return layer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeRr3GtWwK6E"
      },
      "source": [
        "#### Activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcVZwcE_wK6F"
      },
      "source": [
        "class ReLU():\n",
        "    \"\"\"\n",
        "    Activation function : ReLU function\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def forward(self,A):\n",
        "        self.A = A\n",
        "        return np.maximum(self.A,0)\n",
        "    \n",
        "    def backward(self,dZ):\n",
        "        \n",
        "        return np.where(self.A>0,dZ,0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc3bzSARwK6F"
      },
      "source": [
        "class Softmax():\n",
        "    \"\"\"\n",
        "    Activation Function : Softmax Function\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def forward(self,A):\n",
        "        \n",
        "        return np.exp(A-np.max(A))/np.sum(np.exp(A-np.max(A)),axis=1,keepdims=True)\n",
        "    \n",
        "    def backward(self,dZ):\n",
        "        return dZ"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnOfhzHiwK6F"
      },
      "source": [
        "#### Mini-batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqOiXryIwK6F"
      },
      "source": [
        "# Mini-batch processing class\n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    Iterator to get the mini-batch\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : ndarray of the following form, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : ndarray of the following form, shape (n_samples, 1)\n",
        "      correct value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      Seeding random numbers in NumPy\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=None):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    \n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1] \n",
        "    \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2fxdDrkwK6F"
      },
      "source": [
        "### 【Problem 1】Creating a 2-D convolutional layer\n",
        "Expand the class Conv1d of 1D convolutional layers to create the class Conv2d of 2D convolutional layers.\n",
        "\n",
        "The formula for forward propagation is as follows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_G5tefgwK6G"
      },
      "source": [
        "#### convolutional layer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q7iydz8wK6H"
      },
      "source": [
        "# 2d convolutional layer class\n",
        "class SimpleConv2d():\n",
        "    \"\"\"\n",
        "    2-D convolutional layer\n",
        "    Parameters\n",
        "    ----------\n",
        "    initializer : Instances of initialization methods\n",
        "    optimizer : Instances of optimization methods\n",
        "    \"\"\"\n",
        "    def __init__(self, F, C, FH, FW, P, S,\n",
        "                 initializer=None,optimizer=None,activation=None):\n",
        "        self.P = P\n",
        "        self.S = S\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        \n",
        "        # Initialize.\n",
        "        # Use the initializer method to initialize self.W and self.B\n",
        "        self.W = self.initializer.W(F,C,FH,FW)\n",
        "        self.B = self.initializer.B(F)\n",
        "        \n",
        "    def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
        "        OH = (H +2*PH -FH)/SH +1\n",
        "        OW = (W +2*PW -FW)/SW +1\n",
        "        return int(OH),int(OW)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        forward \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "            Input\n",
        "        Returns\n",
        "        ----------\n",
        "        A : ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "            Output\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        N,C,H,W = self.X.shape\n",
        "        F,C,FH,FW = self.W.shape\n",
        "        \n",
        "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
        "        \n",
        "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "\n",
        "        A = np.zeros([N,F,OH,OW])\n",
        "\n",
        "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
        "\n",
        "        # Batch\n",
        "        for n in range(N):\n",
        "            # Output channels\n",
        "            for ch in range(F):\n",
        "                # Vertical slide\n",
        "                for row in range(0,H,self.S):\n",
        "                    # Horizontal Slide\n",
        "                    for col in range(0,W,self.S):\n",
        "                        A[n,ch,row,col] = \\\n",
        "                        np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "                               *self.W[ch,:,:,:]) \\\n",
        "                        +self.B[ch]\n",
        "        \n",
        "        return  self.activation.forward(A)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        backward\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "            The gradient flowed in from behind.\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "            forward slope\n",
        "        \"\"\"\n",
        "        \n",
        "        dA = self.activation.backward(dZ)\n",
        "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
        "        \n",
        "        dZ = np.zeros(self.X_pad.shape)\n",
        "        self.dW = np.zeros(self.W.shape)\n",
        "        self.dB = np.zeros(self.B.shape)\n",
        "        \n",
        "        # dZ\n",
        "        # Batch\n",
        "        for n in range(N):\n",
        "            # Output channels\n",
        "            for ch in range(F):\n",
        "                # Vertical slide\n",
        "                for row in range(0,H,self.S):\n",
        "                    # Horizontal Slide\n",
        "                    for col in range(0,W,self.S):\n",
        "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
        "                \n",
        "        dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
        "        dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
        "\n",
        "        dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "        dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "                \n",
        "        # dW\n",
        "        # Batch\n",
        "        for n in range(N):\n",
        "            # Output channels\n",
        "            for ch in range(F):\n",
        "                # Vertical slide\n",
        "                for row in range(OH):\n",
        "                    # Horizontal Slide\n",
        "                    for col in range(OW):\n",
        "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "        \n",
        "        # dB\n",
        "        # Output channels\n",
        "        for ch in range(F):\n",
        "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "        \n",
        "        # Update\n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return dZ"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hwp3fknwK6H"
      },
      "source": [
        "### 【Problem 2】Output size after 2-D convolution\n",
        "Convolution changes the size of the feature map.  \n",
        "How it changes can be obtained from the following formula.  \n",
        "Create a function to do this calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kG8fOwXwK6I"
      },
      "source": [
        "def output_shape2d(IH=5,IW=5,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1):\n",
        "    OH = (IH +2*PH -FH)/SH +1\n",
        "    OW = (IW +2*PW -FW)/SW +1\n",
        "    return int(OH),int(OW)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3_fksagCwK6I",
        "outputId": "84ef56a1-c9e8-4740-8e73-933bc696bec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(output_shape2d(IH=6,IW=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8_bnJMtwK6I"
      },
      "source": [
        "#### Experiment with 2D convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0GlEE_HowK6I",
        "outputId": "a7b56fcc-6d90-4b35-cfb3-26a64251b571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N,C,H,W = (5,1,28,28)\n",
        "F,C,FH,FW = (4,1,3,3)\n",
        "\n",
        "S = 1 #Fixed for now\n",
        "P = 1\n",
        "\n",
        "OH,OW = output_shape2d(H,W,P,P,FH,FW,S,S)\n",
        "\n",
        "A = np.zeros([N,F,OH,OW])\n",
        "\n",
        "X_sample = X[0:N].reshape(N,C,H,W)\n",
        "X_pad = np.pad(X_sample,((0,0),(0,0),(P,P),(P,P)))\n",
        "w = np.ones([F,C,FH,FW])\n",
        "B = np.ones(F)\n",
        "\n",
        "# Forward\n",
        "\n",
        "# Batch\n",
        "for n in range(N):\n",
        "    # Output channels\n",
        "    for ch in range(F):\n",
        "        # Vertical slide\n",
        "        for row in range(0,H,S):\n",
        "            # Horizontal Slide\n",
        "            for col in range(0,W,S):\n",
        "                A[n,ch,row,col] = \\\n",
        "                np.sum(X_pad[n,:,row:row+FH,col:col+FW]*w[ch,:,:,:]) +B[ch]\n",
        "                \n",
        "print('A.shape:',A.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A.shape: (5, 4, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6q-XJLqwK6J",
        "outputId": "ba918c8a-f908-4626-8305-28bd7e8382f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Backward\n",
        "dA = np.ones(A.shape)\n",
        "\n",
        "dZ = np.zeros(X_pad.shape)\n",
        "dW = np.zeros(w.shape)\n",
        "dB = np.zeros(B.shape)\n",
        "\n",
        "# dZ\n",
        "# Batch\n",
        "for n in range(N):\n",
        "    # Output channels\n",
        "    for ch in range(F):\n",
        "        # Vertical slide\n",
        "        for row in range(0,H,S):\n",
        "            # Horizontal Slide\n",
        "            for col in range(0,W,S):\n",
        "                dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*w[ch,:,:,:]\n",
        "                \n",
        "dl_rows = range(P),range(H+P,H+2*P,1)\n",
        "dl_cols = range(P),range(W+P,W+2*P,1)\n",
        "\n",
        "dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "                \n",
        "# dW\n",
        "# Batch\n",
        "for n in range(N):\n",
        "    # Output channels\n",
        "    for ch in range(F):\n",
        "        # Vertical slide\n",
        "        for row in range(OH):\n",
        "            # Horizontal Slide\n",
        "            for col in range(OW):\n",
        "                dW[ch,:,:,:] += dA[n,ch,row,col]*X_pad[n,:,row:row+FH,col:col+FW]\n",
        "                \n",
        "# dB\n",
        "# Output channels\n",
        "for ch in range(F):\n",
        "    dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "                \n",
        "print('dZ.shape:',dZ.shape)\n",
        "print('dW.shape:',dW.shape)\n",
        "print('dB.shape:',dB.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dZ.shape: (5, 1, 28, 28)\n",
            "dW.shape: (4, 1, 3, 3)\n",
            "dB.shape: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VkJ-KlgwK6J"
      },
      "source": [
        "### 【Problem 3】Creating a maximum pooling layer\n",
        "Create a class MaxPool2D for the maximum pooling layer.  \n",
        "Some parts of the pooling layer are easier to understand if they are not expressed in mathematical form, but if they are expressed in mathematical form, the forward propagation looks like this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViTwMwPvwK6J"
      },
      "source": [
        "class MaxPool2D():\n",
        "    \n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "        \n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PS = self.P\n",
        "        PH,PW = int(OH/PS),int(OW/PS)\n",
        "        \n",
        "        self.params = N,F,OH,OW,PS,PH,PW\n",
        "        \n",
        "        # Pooling filter\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "        \n",
        "        for n in range(N):\n",
        "            # Output channels\n",
        "            for ch in range(F):\n",
        "                # Vertical slide\n",
        "                for row in range(PH):\n",
        "                    # Horizontal Slide\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] = \\\n",
        "                        np.max(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "                        \n",
        "                        self.Pindex[n,ch,row,col] = \\\n",
        "                        np.argmax(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "                        \n",
        "        return self.PA\n",
        "    \n",
        "    def backward(self,dA):\n",
        "        \n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        \n",
        "        for n in range(N):\n",
        "            # Output channels\n",
        "            for ch in range(F):\n",
        "                # Vertical slide\n",
        "                for row in range(PH):\n",
        "                    # Horizontal Slide\n",
        "                    for col in range(PW):\n",
        "                        idx = self.Pindex[n,ch,row,col]\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            if i == idx:\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "                            else:\n",
        "                                tmp[i] = 0\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        \n",
        "        return dP"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_K85cvI6wK6J",
        "outputId": "6fcd66e9-4585-47fa-efcb-1a1f16d41e1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
        "print(X)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[8 3 2 4 6 2]\n",
            "   [5 2 2 5 3 3]\n",
            "   [0 7 4 2 1 2]\n",
            "   [7 7 0 3 1 4]\n",
            "   [7 6 3 1 8 5]\n",
            "   [5 0 3 6 1 0]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BvKBDUFAwK6J",
        "outputId": "3394110e-8804-49cb-8bf3-963be431518f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Pooling = MaxPool2D(P=2)\n",
        "A = Pooling.forward(X)\n",
        "\n",
        "print(A.shape)\n",
        "print(A)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 3, 3)\n",
            "[[[[8. 5. 6.]\n",
            "   [7. 4. 4.]\n",
            "   [7. 6. 8.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2G8YfJCwK6K",
        "outputId": "698a5d4a-a2d4-450c-f1b6-bf1d1365cc2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Pooling.Pindex"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0., 3., 0.],\n",
              "         [1., 0., 3.],\n",
              "         [0., 3., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_Wih4miwK6K",
        "outputId": "800d5289-2dab-47b0-d1f0-7f0ca4429ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
        "print(dA)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[7 5 5]\n",
            "   [7 5 2]\n",
            "   [4 4 2]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL5y1XmHwK6K",
        "outputId": "17db5bce-6ad5-4583-b98f-a632eee5e78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dZ = Pooling.backward(dA)\n",
        "\n",
        "print(dZ)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[7. 0. 0. 0. 5. 0.]\n",
            "   [0. 0. 0. 5. 0. 0.]\n",
            "   [0. 7. 5. 0. 0. 0.]\n",
            "   [0. 0. 0. 0. 0. 2.]\n",
            "   [4. 0. 0. 0. 2. 0.]\n",
            "   [0. 0. 0. 4. 0. 0.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMhiYqepwK6L"
      },
      "source": [
        "### 【Problem 4】(Advanced Problem) Creating Average Pooling\n",
        "Create a class AveragePool2D for the average pooling layer.\n",
        "\n",
        "This is a pooling layer that outputs the average value instead of the maximum value in a range.\n",
        "\n",
        "In image recognition, the maximum pooling layer is commonly used, while the average pooling is not often used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th8daQ5kwK6L"
      },
      "source": [
        "class AveragePool2D():\n",
        "    \n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "        \n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PS = self.P\n",
        "        PH,PW = int(OH/PS),int(OW/PS)\n",
        "        \n",
        "        self.params = N,F,OH,OW,PS,PH,PW\n",
        "        \n",
        "        # Pooling filter\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        \n",
        "        for n in range(N):\n",
        "            # Output channels\n",
        "            for ch in range(F):\n",
        "                # Vertical slide\n",
        "                for row in range(PH):\n",
        "                    # Horizontal Slide\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] = \\\n",
        "                        np.mean(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "                        \n",
        "        return self.PA\n",
        "    \n",
        "    def backward(self,dA):\n",
        "        \n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        \n",
        "        for n in range(N):\n",
        "            # Output channels\n",
        "            for ch in range(F):\n",
        "                # Vertical slide\n",
        "                for row in range(PH):\n",
        "                    # Horizontal Slide\n",
        "                    for col in range(PW):\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            tmp[i] = dA[n,ch,row,col]/(PS*PS)\n",
        "\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        \n",
        "        return dP"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GZeorsTwK6L",
        "outputId": "ea824b93-7331-4c59-8872-5dc31cb2f744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
        "print(X)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[1 4 7 3 0 0]\n",
            "   [5 1 1 6 6 0]\n",
            "   [8 6 5 0 8 4]\n",
            "   [6 1 4 2 7 0]\n",
            "   [1 8 2 8 8 0]\n",
            "   [2 7 0 2 3 6]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMOZpmCNwK6L",
        "outputId": "b4748671-e93a-446d-dad5-374907614beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Pooling = AveragePool2D(P=2)\n",
        "A = Pooling.forward(X)\n",
        "\n",
        "print(A.shape)\n",
        "print(A)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 3, 3)\n",
            "[[[[2.75 4.25 1.5 ]\n",
            "   [5.25 2.75 4.75]\n",
            "   [4.5  3.   4.25]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khNbmi_kwK6M",
        "outputId": "6b38a2b0-9f48-4690-ec91-4125a7460c19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
        "print(dA)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[6 1 0]\n",
            "   [8 0 1]\n",
            "   [2 8 6]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5njJx88SwK6M",
        "outputId": "b8c1da46-8bce-4fd1-9c5d-1f183627abcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dZ = Pooling.backward(dA)\n",
        "\n",
        "print(dZ)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[1.5  1.5  0.25 0.25 0.   0.  ]\n",
            "   [1.5  1.5  0.25 0.25 0.   0.  ]\n",
            "   [2.   2.   0.   0.   0.25 0.25]\n",
            "   [2.   2.   0.   0.   0.25 0.25]\n",
            "   [0.5  0.5  2.   2.   1.5  1.5 ]\n",
            "   [0.5  0.5  2.   2.   1.5  1.5 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdMUr2VLwK6M"
      },
      "source": [
        "### 【Problem 5】Flatten\n",
        "Create a Flatten class for smoothing.\n",
        "\n",
        "In the forward direction, reshape the three dimensions of channel, height, and width to one dimension. The values are recorded and reshaped again in the backward direction.\n",
        "\n",
        "By sandwiching this smoothing class in between, we can create an array suitable for all coupled layers before output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGFt2uxFwK6M"
      },
      "source": [
        "class Flatten:\n",
        "    def __ini__(self,):\n",
        "        pass\n",
        "    def forward(self,X):\n",
        "        self.shape = X.shape\n",
        "        return X.reshape(len(X),-1)\n",
        "\n",
        "    def backward(self,X):\n",
        "        return X.reshape(self.shape)        "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uJcS2MHwK6M",
        "outputId": "a50ef90f-2b8e-49ec-ee02-50dd66f52b21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TEST = np.zeros([20,2,5,5])\n",
        "flt = Flatten()\n",
        "flat_forward = flt.forward(TEST)\n",
        "print('Forward_shape:',flat_forward.shape)\n",
        "print('Backward_shape:',flt.backward(flat_forward).shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward_shape: (20, 50)\n",
            "Backward_shape: (20, 2, 5, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fux5jvxuwK6N"
      },
      "source": [
        "### 【Problem 6】Training and Estimation\n",
        "Use the Conv2d you created to train and estimate MNIST and calculate the Accuracy.\n",
        "\n",
        "Please aim to make it work first, even if the accuracy is low."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnkAOmCEwK6N"
      },
      "source": [
        "# Scratch CNN\n",
        "class Scratch2dCNNClassifier():\n",
        "    \"\"\"\n",
        "    N-Layer Convolutional Neural Network Classifier\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    self.n_epoch : epoch number\n",
        "    self.n_batch : Number of batches\n",
        "    self.verbose : Visualizing the learning process\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
        "        # Parameters\n",
        "        self.n_epoch = n_epoch\n",
        "        self.n_batch = n_batch\n",
        "        self.verbose = verbose\n",
        "        self.log_loss = np.zeros(self.n_epoch)\n",
        "        self.log_acc = np.zeros(self.n_epoch)\n",
        "        self.NN = NN\n",
        "        self.CNN = CNN\n",
        "        \n",
        "    def loss_function(self,y,yt):\n",
        "        delta = 1e-7\n",
        "        return -np.mean(yt*np.log(y+delta))\n",
        "    \n",
        "    def accuracy(self,Z,Y):\n",
        "        return accuracy_score(Y,Z)\n",
        "                \n",
        "    def fit(self, X, y, X_val=False, y_val=False):\n",
        "        \"\"\"\n",
        "        Train a neural network classifier.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray of the following form, shape (n_samples, n_features)\n",
        "            Features of training data\n",
        "        y : ndarray of the following form, shape (n_samples, )\n",
        "            Correct answer value of training data\n",
        "        X_val : ndarray of the following form, shape (n_samples, n_features)\n",
        "            Features of validation data\n",
        "        y_val : ndarray of the following form, shape (n_samples, )\n",
        "            Correct value of validation data\n",
        "        \"\"\"\n",
        "        for epoch in range(self.n_epoch):\n",
        "            # Mini-batch processing\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
        "            \n",
        "            self.loss = 0\n",
        "            for mini_X_train, mini_y_train in get_mini_batch:\n",
        "                                \n",
        "                # Forward propagation\n",
        "                forward_data = mini_X_train[:,np.newaxis,:,:]\n",
        "                \n",
        "                # Conv\n",
        "                for layer in range(len(self.CNN)):\n",
        "                    forward_data = self.CNN[layer].forward(forward_data)\n",
        "                \n",
        "                # Flatten\n",
        "                flt = Flatten()\n",
        "                forward_data = flt.forward(forward_data)\n",
        "                \n",
        "                # NN\n",
        "                for layer in range(len(self.NN)):\n",
        "                    forward_data = self.NN[layer].forward(forward_data)\n",
        "                    \n",
        "                # Predicted value\n",
        "                Z = forward_data\n",
        "                \n",
        "                # Back propagation\n",
        "                backward_data = (Z - mini_y_train)/self.n_batch\n",
        "                for layer in range(len(self.NN)-1,-1,-1):\n",
        "                    backward_data = self.NN[layer].backward(backward_data)\n",
        "                   \n",
        "                    \n",
        "                backward_data = flt.backward(backward_data)\n",
        "                \n",
        "                for layer in range(len(self.CNN)-1,-1,-1):\n",
        "                    backward_data = self.CNN[layer].backward(backward_data)\n",
        "                \n",
        "                # Loss function\n",
        "                self.loss += self.loss_function(Z,mini_y_train)\n",
        "                \n",
        "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
        "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))\n",
        "            \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Estimate using a neural network classifier.。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray of the following form, shape (n_samples, n_features)\n",
        "            Sample\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            ndarray of the following, shape (n_samples, 1)\n",
        "            Estimation results\n",
        "        \"\"\"\n",
        "        pred_data = X[:,np.newaxis,:,:]\n",
        "        \n",
        "        # Conv\n",
        "        for layer in range(len(self.CNN)):\n",
        "            pred_data = self.CNN[layer].forward(pred_data)\n",
        "                \n",
        "        pred_data = flt.forward(pred_data)\n",
        "        \n",
        "        # NN\n",
        "        for layer in range(len(self.NN)):\n",
        "            pred_data = self.NN[layer].forward(pred_data)\n",
        "            \n",
        "        return np.argmax(pred_data,axis=1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd2itkg0wK6N"
      },
      "source": [
        "# All bonding layers\n",
        "NN = {0:FC(7840, 400, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "      1:FC(400, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "      2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
        "     }"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA0duXqdwK6N"
      },
      "source": [
        "# Convolutional layers\n",
        "CNN = {0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1, S=1,\n",
        "                      initializer=SimpleInitializerConv2d(),\n",
        "                      optimizer=SGD(),\n",
        "                      activation=ReLU())}"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at4_QFo8wK6O",
        "outputId": "8cf5006a-668d-474c-bc3c-0491f8cf182e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Learning\n",
        "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=10,n_batch=200,verbose=False)\n",
        "\n",
        "cnn1.fit(X_train[0:1000],y_train[0:1000])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou7d7r_BwK6O",
        "outputId": "4adacc49-9c51-433a-9432-242f3fc03321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Estimate\n",
        "y_pred = cnn1.predict(X_valid[0:100])\n",
        "\n",
        "# Positive solution rate\n",
        "accuracy = accuracy_score(np.argmax(y_valid[0:100],axis=1), y_pred)\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:0.870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9QTh7iR_wK6O",
        "outputId": "79445f9d-ed22-42da-a548-db7001a3c4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Visualize the loss function for each epoch\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "fig=plt.subplots(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('LOSS')\n",
        "plt.plot(cnn1.log_loss,'bo--')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('ACC')\n",
        "plt.plot(cnn1.log_acc,'rs--');"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY5QpsTUwK6O"
      },
      "source": [
        "* As a result of running it on the mini-data, the LOSS is coming down, and the percentage of correct answers, as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtP8R-9hwK6Q"
      },
      "source": [
        "### 【Problem 9】Calculating output size and number of parameters\n",
        "When building a CNN model, it is necessary to calculate the number of features in advance at the stage of inputting them into the all-connected layer.\n",
        "\n",
        "Also, when dealing with huge models, the calculation of the number of parameters becomes essential due to memory and computation speed. The framework can display the number of parameters for each layer, but without understanding the meaning, it is impossible to make appropriate adjustments.\n",
        "\n",
        "Calculate the output size and the number of parameters for the following three convolutional layers. For the number of parameters, also consider the bias term.\n",
        "\n",
        "1.\n",
        "\n",
        "* Input size : 144x144, 3 channels\n",
        "* Filter size : 3×3, 6 channels\n",
        "* Stride : 1\n",
        "* Padding : None\n",
        "\n",
        "→ Output size : 6×142×142, Number of parameters : 168 (Weight 162, Bias 6)\n",
        "\n",
        "2.\n",
        "\n",
        "* Input size : 60×60, 24 channels\n",
        "* Filter size: 3×3, 48 channels\n",
        "* Stride : 1\n",
        "* Padding : None\n",
        "\n",
        "→ Output size : 48×58×58, Number of parameters : 10416(Weight 10368, Bias 48)\n",
        "\n",
        "3.\n",
        "\n",
        "* Input size: 20x20, 10 channels\n",
        "* Filter size: 3×3, 20 channels\n",
        "* Stride : 2\n",
        "* Padding : None\n",
        "\n",
        "→ Output size: 20x9x9, Number of parameters: 1820 (weights 1800, bias 20)\n",
        "\n",
        "The last example is a case where the convolution cannot be done just right. The framework sometimes does not look at the extra pixels, so please consider that case in your calculations. This is an example of why this kind of setting is not desirable, because it will result in missing edges."
      ]
    }
  ]
}